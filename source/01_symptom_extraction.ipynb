{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7de3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import logging\n",
    "from threading import Semaphore\n",
    "import os\n",
    "import pandas as pd\n",
    "from pymetamap import MetaMap\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e557814",
   "metadata": {},
   "source": [
    "# Symptom Extraction using Metamap\n",
    "\n",
    "This notebook implements the BiLSTM model which will take TF-IDF based symptom representation and Word2Vec based symptom representation and predicts diagnoses codes.\n",
    "\n",
    "---\n",
    "\n",
    "- Input : symptom_disease_dict_{RUN_TAG}.json - Contains HADM_ID to Symptom text and Diagnosis mapping as json object\n",
    "- Input : icd9_dict_{RUN_TAG}.json - Contains ICD9 Codes of TOP N Diagnoses\n",
    "- Input : weight_i_j_norm{tag}.csv - TF-IDF weights for symptom representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd33bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory : /Users/vijaymi/Studies/CS-598-DL4Health/Project/135-Disease-Inference-Method/disease_pred_using_bilstm/source\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory : {cwd}\")\n",
    "# Metamap needs to be installed locally for this to work\n",
    "METAMAP_PATH = cwd + \"/../../public_mm\"\n",
    "\n",
    "# Data is not stored as part of project because of its restricted use.\n",
    "data_dir = cwd + \"/../../data/\"\n",
    "NOTES_FILE = data_dir + 'filtered_notes.csv'\n",
    "DIAG_FILE = data_dir +  'DIAGNOSES_ICD.csv'\n",
    "DIAG_DICT_FILE = data_dir + 'D_ICD_DIAGNOSES.csv'\n",
    "SYMPTOMS_FILE = \"Symptoms.txt\"\n",
    "mm = MetaMap.get_instance(METAMAP_PATH + '/bin/metamap18')\n",
    "IRRELEVANT_SECTIONS = [\n",
    "    \"SOCIAL HISTORY:\",\n",
    "    \"MEDICATION ON ADMISSION:\",\n",
    "    \"DISCHARGE DIAGNOSIS:\",\n",
    "    \"ADMISSION DATE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcacc6",
   "metadata": {},
   "source": [
    "### Load Data from MIMIC-III dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e29c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    notes_data = pd.read_csv(NOTES_FILE)\n",
    "    print(notes_data.head())\n",
    "    diag_codes = pd.read_csv(DIAG_FILE)\n",
    "    diag_dict = pd.read_csv(DIAG_DICT_FILE)\n",
    "    return notes_data, diag_codes, diag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6938fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INDEX ROW_ID SUBJECT_ID HADM_ID CHARTDATE CHARTTIME STORETIME  \\\n",
      "0     0    174      22532  167853    8/4/51       NaN       NaN   \n",
      "1     1    175      13702  107527   6/14/18       NaN       NaN   \n",
      "2     2    176      13702  167118   5/25/19       NaN       NaN   \n",
      "3     3    177      13702  196489   8/18/24       NaN       NaN   \n",
      "4     4    178      26880  135453   3/25/62       NaN       NaN   \n",
      "\n",
      "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0  Discharge summary      Report   NaN      NaN   \n",
      "1  Discharge summary      Report   NaN      NaN   \n",
      "2  Discharge summary      Report   NaN      NaN   \n",
      "3  Discharge summary      Report   NaN      NaN   \n",
      "4  Discharge summary      Report   NaN      NaN   \n",
      "\n",
      "                                                TEXT  \n",
      "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
      "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
      "2  Admission Date:  [**2119-5-4**]              D...  \n",
      "3  Admission Date:  [**2124-7-21**]              ...  \n",
      "4  Admission Date:  [**2162-3-3**]              D...  \n"
     ]
    }
   ],
   "source": [
    "notes_data, diag_codes, diag_dict = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab6c08",
   "metadata": {},
   "source": [
    "#### Using nltk package, remove words in negated context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6df2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_negative_context_words(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens_neg_marked = nltk.sentiment.util.mark_negation(tokens)\n",
    "    tokens_without_negative_words = [word for word in tokens_neg_marked if not word.endswith(\"_NEG\")]\n",
    "    return \" \".join(tokens_without_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad1ce84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sam is having cough but not .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"Sam is having cough but not fever.\"\n",
    "remove_negative_context_words(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1a7c6",
   "metadata": {},
   "source": [
    "#### Remove some irrevalent section fron Notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4449335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_sections(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    output_lines = []\n",
    "    skip = False\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # If Skipping lines, look for end of section indicator - new line for now.\n",
    "        if skip:\n",
    "            if not line:\n",
    "                skip = False\n",
    "                continue\n",
    "        else:\n",
    "            for section_name in IRRELEVANT_SECTIONS:\n",
    "                if line.upper().startswith(section_name):\n",
    "                    # print(f\"Skipping section : {line}\")\n",
    "                    skip = True\n",
    "\n",
    "            if not skip:\n",
    "                output_lines.append(line)\n",
    "    return \"\\n\".join(output_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b73013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCLINICAL NOTES: Person is having fever.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "SOCIAL HISTORY: Some words here.\n",
    "\n",
    "CLINICAL NOTES: Person is having fever.\n",
    "\"\"\"\n",
    "\n",
    "remove_irrelevant_sections(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb53909",
   "metadata": {},
   "source": [
    "### Extracting Symptoms from clinical text using Metamap\n",
    "\n",
    "Metamap download link - https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/run-locally/MainDownload.html <br>\n",
    "Installation link - https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/documentation/Installation.html <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6eb8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_symptoms_using_metamap(text):\n",
    "    symptoms = []\n",
    "    # print(text)\n",
    "    try:\n",
    "        concepts, error = mm.extract_concepts([text])\n",
    "        # print(f\"concepts : {concepts}\")\n",
    "        for concept in concepts:\n",
    "            if hasattr(concept, \"semtypes\"):\n",
    "                if \"sosy\" in concept.semtypes or \"dsyn\" in concept.semtypes:\n",
    "                    # print(f\"concept : {concept}\")\n",
    "                    symptoms.append(concept.preferred_name)\n",
    "        return symptoms\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred {e} \")\n",
    "        logger.error(f\"Exception occurred {e} \")\n",
    "        return symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "882e1d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tuberculosis',\n",
       " 'Macrophage Activation Syndrome',\n",
       " 'Osteoporosis',\n",
       " 'Pleural effusion disorder',\n",
       " 'Mass of body region']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"\"\" Service:\n",
    "ADDENDUM:\n",
    "\n",
    "RADIOLOGIC STUDIES:  Radiologic studies also included a chest\n",
    "CT, which confirmed cavitary lesions in the left lung apex\n",
    "consistent with infectious process/tuberculosis.  This also\n",
    "moderate-sized left pleural effusion.\n",
    "\n",
    "HEAD CT:  Head CT showed no intracranial hemorrhage or mass\n",
    "effect, but old infarction consistent with past medical\n",
    "history.\n",
    "\n",
    "ABDOMINAL CT:  Abdominal CT showed lesions of\n",
    "T10 and sacrum most likely secondary to osteoporosis. These can\n",
    "be followed by repeat imaging as an outpatient.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "extract_symptoms_using_metamap(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86c646",
   "metadata": {},
   "source": [
    "### Integrating all above functions to extract symptoms from Clinical notes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c64a6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_notes(text):\n",
    "    # print(f\"Discharge Summary : {text}\")\n",
    "    # Remove non-relevant sections\n",
    "    filtered_text = remove_irrelevant_sections(text)\n",
    "\n",
    "    # Remove negative words\n",
    "    filtered_neg_text = remove_negative_context_words(filtered_text)\n",
    "\n",
    "    # Identify relevant concepts from text\n",
    "    symptoms = extract_symptoms_using_metamap(filtered_neg_text)\n",
    "    return symptoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9f6402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(notes_data, symptoms_list):\n",
    "    with semaphore_object:\n",
    "        print(f\"printing for {symptoms_list}\")\n",
    "        with open(DATA_BASE_PATH + SYMPTOMS_FILE + \"-\" + timestamp, 'a') as writer:\n",
    "            for idx, symptoms in enumerate(symptoms_list):\n",
    "                print(f\"notes_data : {notes_data.iloc[idx, 0]}\")\n",
    "                writer.write(str(notes_data.iloc[idx, 0]) + \",\" + str(notes_data.iloc[idx, 1])\n",
    "                             + \",\" + str(notes_data.iloc[idx, 2])\n",
    "                             + \",\" + str(notes_data.iloc[idx, 3]) + \",\")\n",
    "                symptom_str = \"|\".join(symptoms)\n",
    "                symptom_str = symptom_str.replace(\",\", \" \")\n",
    "                writer.write(symptom_str)\n",
    "                writer.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9d0ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(notes_data):\n",
    "    global record_processed\n",
    "    print(notes_data.shape)\n",
    "    record_processed += notes_data.shape[0]\n",
    "    if record_processed <= LAST_RECORD_DONE:\n",
    "        print(f\"Skipping - record processed - {record_processed}\")\n",
    "        return\n",
    "\n",
    "    print(f\"processing record : {record_processed}\")\n",
    "    symptoms_list = []\n",
    "    number_of_rec = notes_data.shape[0]\n",
    "    for index in range(number_of_rec):\n",
    "        symptoms = process_notes(notes_data.iloc[index, 11])\n",
    "        print(f\"Symptoms : {symptoms}\")\n",
    "        symptoms_list.append(symptoms)\n",
    "\n",
    "    save_to_file(notes_data, symptoms_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8e922e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Pre-processing starting now!\")\n",
    "    data_iterator = pd.read_csv(DATA_BASE_PATH + NOTES_FILE, chunksize=10)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        executor.map(process_chunk, data_iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Train BiLSTM Model\n",
    "\n",
    "Here we will define and train the BiLSTM model for input data obtained by using Word2Vec for symptom embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Symptom <-> Disease Data and Word2Vec Model\n",
    "\n",
    "We have prepared input output pairs for symptoms and diseases [(x1, y1), (x2, y2).....], and stored them as a dictionary. Here we will load that data which will act as training and testing dataset. Also, we will load the trained Word2Vec model which will be used to get the symptom embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory : /Users/ratanbajpai/Education/UIUC/DLH/project/src\n",
      "Data directory : /Users/ratanbajpai/Education/UIUC/DLH/project/src/../data/\n",
      "Model directory : /Users/ratanbajpai/Education/UIUC/DLH/project/src/model/\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = cwd + \"/../data/\"\n",
    "model_dir = cwd + \"/model/\"\n",
    "print(f\"Current working directory : {cwd}\")\n",
    "print(f\"Data directory : {data_dir}\")\n",
    "print(f\"Model directory : {model_dir}\")\n",
    "\n",
    "# Load the symptom disease dictionary\n",
    "with open(data_dir + \"symptom_disease_dict.csv\", 'r') as f:\n",
    "    symptom_disease_dict = json.load(f)\n",
    "len(symptom_disease_dict)\n",
    "\n",
    "with open(data_dir + \"icd9_dict.csv\", 'r') as f:\n",
    "    icd9_dict = json.load(f)\n",
    "\n",
    "# Load a saved word2vec model \n",
    "word2vec_model = gensim.models.Word2Vec.load(model_dir + 'word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43651"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dictionary to list of values i.e. [(x1, y1), (x2, y2).....]\n",
    "symptom_disease_list = list(symptom_disease_dict.values())\n",
    "len(symptom_disease_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset\n",
    "\n",
    "MAX_SYMPTOMS = 50\n",
    "MAX_DISEASE = 50\n",
    "NUM_FEATURES = 128\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, xypair_list, icd9_dict, model_w2v):\n",
    "        \n",
    "        # Set data and model variables\n",
    "        self.xypair_list = xypair_list\n",
    "        self.model_w2v = model_w2v\n",
    "        self.icd9_dict = icd9_dict\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xypair_list)\n",
    "    \n",
    "    def create_symp_vec(self, symptom):\n",
    "        symp_words = symptom.split()\n",
    "        symp_vec = np.zeros(NUM_FEATURES, dtype=np.float64)\n",
    "        for word in symp_words:\n",
    "            # Get the word embedding\n",
    "            key = re.sub(r\"[^a-zA-Z0-9]\",\"\", word.lower())\n",
    "            if key in self.model_w2v:\n",
    "                symp_vec = symp_vec + self.model_w2v[key]\n",
    "        symp_vec = symp_vec / len(symp_words)\n",
    "        return symp_vec\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            Output:\n",
    "            symptpm vector (X) : length of each symptom vector (128) x max number of symptoms (50)\n",
    "            diagnoses vector (Y) = diagnosed disease vector for these symptoms (50)\n",
    "            symptom count = number of symtoms for current record\n",
    "        \"\"\"\n",
    "        symptom_list = self.xypair_list[index][0]\n",
    "        disease_list = self.xypair_list[index][1]\n",
    "        \n",
    "        # Create a 2d vector of symptoms (X)\n",
    "        symp_vec = np.zeros((NUM_FEATURES, MAX_SYMPTOMS), dtype=np.float64)\n",
    "        \n",
    "        # We take max of 50 symptoms from each discharge summaries note\n",
    "        for col, symptom in enumerate(symptom_list[:50]):\n",
    "            symp_vec[:, col] = self.create_symp_vec(symptom)\n",
    "            \n",
    "        # Create a 1d vector of diseases (Y)\n",
    "        disease_vec = np.zeros(MAX_DISEASE, dtype=np.float32)\n",
    "        for disease in disease_list:\n",
    "            if disease in self.icd9_dict.keys():\n",
    "                index = self.icd9_dict[disease]\n",
    "                disease_vec[index] = 1\n",
    "        \n",
    "        return torch.tensor(symp_vec.T, dtype=torch.float), torch.tensor(disease_vec, dtype=torch.float), len(symptom_list[:50])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  43651\n"
     ]
    }
   ],
   "source": [
    "# Instantiate custom dataset\n",
    "dataset = CustomDataset(symptom_disease_list, icd9_dict, word2vec_model)\n",
    "print('Dataset size: ', len(dataset))\n",
    "\n",
    "# Define train and test sizes\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-49c2bd2290cf>:26: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if key in self.model_w2v:\n",
      "<ipython-input-78-49c2bd2290cf>:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  symp_vec = symp_vec + self.model_w2v[key]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1303, -0.0605,  0.1260,  ...,  0.0597,  0.0214, -0.2647],\n",
       "         [-0.0374, -0.3420, -0.0076,  ..., -0.1074,  0.1338, -0.1693],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 11)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size : 43651\n",
      "symptom_item : torch.Size([50, 128])\n",
      "diag_item : tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-49c2bd2290cf>:26: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if key in self.model_w2v:\n",
      "<ipython-input-78-49c2bd2290cf>:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  symp_vec = symp_vec + self.model_w2v[key]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0763, -0.1303, -0.2874,  ...,  0.3420, -0.5229, -0.1654],\n",
       "        [-0.1053, -0.2726, -0.3009,  ...,  0.2681, -0.2480, -0.0882],\n",
       "        [ 0.4527, -0.0143,  0.0306,  ..., -0.3816,  0.1335,  0.2715],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Dataset size : {len(dataset)}\")\n",
    "symptom_item, diag_item, symptom_len = dataset[0]\n",
    "print(f\"symptom_item : {symptom_item.shape}\")\n",
    "print(f\"diag_item : {diag_item}\")\n",
    "symptom_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseaseSymptomLstm(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(DiseaseSymptomLstm, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=0.8)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, symp_length):\n",
    "        # Perform forward step\n",
    "        out, (ht, ct) = self.bilstm(x)\n",
    "        \n",
    "        # print(f\"out.shape : {out.shape}, ht.shape : {ht.shape}, ct.shape : {ct.shape}\")\n",
    "        # returning last layer of output from hidden state\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        out = self.sigmoid(out)\n",
    "        # Return model output\n",
    "        return out\n",
    "\n",
    "model = DiseaseSymptomLstm(128, 256, 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "DISEASE_THRESHOLD = 0.20\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    \n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: model\n",
    "        test_loader: dataloader\n",
    "        \n",
    "    OUTPUT:\n",
    "        precision: overall micro precision score\n",
    "        recall: overall micro recall score\n",
    "        f1: overall micro f1 score\n",
    "        \n",
    "    REFERENCE: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for sequences, labels, symp_len in test_loader:\n",
    "        # your code here\n",
    "        y_prob = model(sequences, symp_len)\n",
    "        y_hat = (y_prob > DISEASE_THRESHOLD).int()\n",
    "        # print(f\"y_prob: {y_hat}\")\n",
    "        # print(f\"labels: {labels}\")\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, labels.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    auc = roc_auc_score(y_true, y_pred, average='micro')\n",
    "    return p, r, f, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-49c2bd2290cf>:26: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if key in self.model_w2v:\n",
      "<ipython-input-78-49c2bd2290cf>:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  symp_vec = symp_vec + self.model_w2v[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.291704\n",
      "Epoch: 1 \t Validation p: 0.39, r:0.57, f: 0.46, auc: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-49c2bd2290cf>:26: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if key in self.model_w2v:\n",
      "<ipython-input-78-49c2bd2290cf>:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  symp_vec = symp_vec + self.model_w2v[key]\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, test_loader, n_epochs):\n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: the model\n",
    "        train_loader: dataloder\n",
    "        val_loader: dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, y_true, symp_len in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # print(f\"sequence.shape {sequences.shape}, len: {symp_len}\")\n",
    "            y_hat = model(sequences, symp_len)\n",
    "#             print(f\"y_hat : {y_hat}\")\n",
    "#             print(f\"y_true : {y_true}\")\n",
    "            \n",
    "            loss = criterion(y_hat, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, auc = eval(model, test_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, auc: {:.2f}'.format(epoch+1, p, r, f, auc))\n",
    "\n",
    "    \n",
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "train(model, train_loader, test_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

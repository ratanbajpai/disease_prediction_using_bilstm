{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0125c6",
   "metadata": {},
   "source": [
    "<h3> Training BiLSTM Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4978a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8264555",
   "metadata": {},
   "source": [
    "# BiLSTM Model Training\n",
    "\n",
    "This notebook implements the BiLSTM model which will take TF-IDF based symptom representation and Word2Vec based symptom representation and predicts diagnoses codes.\n",
    "\n",
    "---\n",
    "\n",
    "- Input : symptom_disease_dict_{RUN_TAG}.json - Contains HADM_ID to Symptom text and Diagnosis mapping as json object\n",
    "- Input : icd9_dict_{RUN_TAG}.json - Contains ICD9 Codes of TOP N Diagnoses\n",
    "- Input : weight_i_j_norm{tag}.csv - TF-IDF weights for symptom representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fe2728c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory : /Users/vijaymi/Studies/CS-598-DL4Health/Project/135-Disease-Inference-Method/disease_pred_using_bilstm/source\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory : {cwd}\")\n",
    "# Let's define some constants that will be used below in our processing\n",
    "MAX_NUMBER_OF_DISEASE = 100\n",
    "MAX_SYMPTOMS = 50\n",
    "BATCH_SIZE=400\n",
    "WORD2VEC_NUM_FEATURES = 128\n",
    "RUN_TAG = f\"_{MAX_NUMBER_OF_DISEASE}_v2.0\"\n",
    "data_dir = cwd + \"/../../data/\"\n",
    "SYMPTOM_DISEASE_DICT_FILE_PATH = data_dir + f\"symptom_disease_dict_{RUN_TAG}.json\"\n",
    "ICD9_FILE_PATH = data_dir + f\"icd9_dict_{RUN_TAG}.json\"\n",
    "SYMPTOM_DICT_FILE_PATH = data_dir + f\"symptoms_dict_{RUN_TAG}.json\"\n",
    "TF_IDF_WEIGHTS_FILE_PATH = data_dir + f\"weight_i_j_{RUN_TAG}.csv\"\n",
    "TF_IDF_NORM_WEIGHTS_FILE_PATH = data_dir + f\"weight_i_j_norm_{RUN_TAG}.csv\"\n",
    "MODEL_DIR = data_dir + \"/word2vec/\"\n",
    "# Word2Vec model will not change much - so keeping fixed file name\n",
    "MODEL_FILE_PATH = MODEL_DIR + f\"word2vec_model_sg_128__v2.0\"\n",
    "DISEASE_THRESHOLD = 0.20\n",
    "SYMPTOM_TO_DIAGNOSE_MODEL_FILE= data_dir + f\"symptom_diagnoses{RUN_TAG}.model\"\n",
    "SYMPTOM_TO_SYMPTOM_MODEL_FILE= data_dir + f\"symptom_symptom{RUN_TAG}.model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8035f",
   "metadata": {},
   "source": [
    "## 1. Loading all the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8834a243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4016</th>\n",
       "      <th>4017</th>\n",
       "      <th>4018</th>\n",
       "      <th>4019</th>\n",
       "      <th>4020</th>\n",
       "      <th>4021</th>\n",
       "      <th>4022</th>\n",
       "      <th>4023</th>\n",
       "      <th>4024</th>\n",
       "      <th>4025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.328974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.200701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.716152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.545272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498214</td>\n",
       "      <td>0.632686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.620580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.490284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2         3         4    5    6    7    8         9  ...  \\\n",
       "0  0.328974  0.0  0.0  0.348214  0.200701  0.0  0.0  0.0  0.0  0.817708  ...   \n",
       "1  0.096579  0.0  0.0  0.171429  0.716152  0.0  0.0  0.0  0.0  0.802083  ...   \n",
       "2  0.545272  0.0  0.0  0.498214  0.632686  0.0  0.0  0.0  0.0  1.000000  ...   \n",
       "3  0.162978  0.0  0.0  0.300000  0.620580  0.0  0.0  0.0  0.0  0.739583  ...   \n",
       "4  0.270624  0.0  0.0  0.294643  0.490284  0.0  0.0  0.0  0.0  0.630208  ...   \n",
       "\n",
       "       4016      4017   4018      4019      4020      4021      4022   4023  \\\n",
       "0  0.090909  0.666667  0.125  0.833333  0.666667  0.714286  0.500000  1.000   \n",
       "1  0.272727  0.000000  0.625  0.500000  0.111111  0.571429  0.333333  0.500   \n",
       "2  0.545455  0.666667  0.375  0.500000  0.666667  0.714286  0.833333  0.875   \n",
       "3  0.090909  0.166667  0.500  0.333333  0.222222  0.285714  0.166667  0.250   \n",
       "4  0.000000  0.166667  0.125  0.500000  0.111111  0.428571  0.500000  0.875   \n",
       "\n",
       "   4024   4025  \n",
       "0   0.2  1.000  \n",
       "1   0.4  0.500  \n",
       "2   0.6  0.000  \n",
       "3   0.0  0.500  \n",
       "4   0.2  0.625  \n",
       "\n",
       "[5 rows x 4026 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd9_dict = None\n",
    "with open(ICD9_FILE_PATH, 'r') as f:\n",
    "            icd9_dict = json.load(f)\n",
    "        \n",
    "symptom_disease_dict = None\n",
    "with open(SYMPTOM_DISEASE_DICT_FILE_PATH, 'r') as f:\n",
    "            symptom_disease_dict = json.load(f)\n",
    "\n",
    "symptoms_dict = None\n",
    "with open(SYMPTOM_DICT_FILE_PATH, 'r') as f:\n",
    "    symptoms_dict = json.load(f)\n",
    "\n",
    "# Loading saved Word2Vec Model \n",
    "word2vec_model = gensim.models.Word2Vec.load(MODEL_FILE_PATH)\n",
    "    \n",
    "tfidf_weights = pd.read_csv(TF_IDF_NORM_WEIGHTS_FILE_PATH)\n",
    "tfidf_weights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcad268",
   "metadata": {},
   "source": [
    "## 2. Symptom to Disease BiLSTM Model (for TF-IDF based Symptom representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf45e64",
   "metadata": {},
   "source": [
    "### 2.1 Define Custom Loader for Symtom to Diagnoses based BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "18fc365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SymptomCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filename, tfidf_weights, word2vec_model):        \n",
    "        self.hadm_id_map = {}\n",
    "        self.word2vec_embedding_cache = {}\n",
    "        self.tfidf_embedding_cache = {}\n",
    "        \n",
    "        # TF-IDF Weights\n",
    "        self.tfidf_weights = tfidf_weights\n",
    "        \n",
    "        # Word2Vec model\n",
    "        self.model_w2v = word2vec_model.wv\n",
    "        \n",
    "        # Symptom dictionary\n",
    "        with open(SYMPTOM_DICT_FILE_PATH, 'r') as f:\n",
    "            self.symptom_dict = json.load(f)\n",
    "        \n",
    "        with open(ICD9_FILE_PATH, 'r') as f:\n",
    "            self.icd9_dict = json.load(f)\n",
    "        \n",
    "        # read in the data files\n",
    "        self.hadm_list = self.process_raw_data(filename)\n",
    "        \n",
    "        \n",
    "    def process_raw_data(self, filename):\n",
    "        symptom_disease_dict = None\n",
    "        with open(filename, 'r') as f:\n",
    "            symptom_disease_dict = json.load(f)\n",
    "        hadm_list = []\n",
    "\n",
    "        # Collecting all records for one admission as a tuple of symptoms list and diagnoses list\n",
    "        # for hadm_id in list(symptom_disease_dict.keys())[:30000]:    \n",
    "        for hadm_id in list(symptom_disease_dict.keys()):            \n",
    "            symp_list, icd9_list = symptom_disease_dict[hadm_id]\n",
    "            \n",
    "            # TF-IDF - Matrix of size (MAX_SYMPTOMS, MAX_NUMBER_OF_DISEASE)\n",
    "            tfidf_symp_vec = self.create_symptom_vector_with_tfidf(symp_list)\n",
    "            if tfidf_symp_vec is None:\n",
    "                continue\n",
    "            \n",
    "            # Word2Vec - Matrix of size (MAX_SYMPTOMS, MAX_NUMBER_OF_DISEASE)\n",
    "            w2v_symp_vec = self.create_symptom_vector_with_word2vec(symp_list)\n",
    "            \n",
    "            # Processing Diagnoses Code - Series of size MAX_NUMBER_OF_DISEASE\n",
    "            diag_vec = self.create_diagnosis_vector(icd9_list)\n",
    "\n",
    "            # Save all three in hadm list\n",
    "            hadm_list.append((tfidf_symp_vec, w2v_symp_vec, diag_vec, symp_list))\n",
    "        \n",
    "        return hadm_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hadm_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            Output:\n",
    "            tf-idf symptpm_vector : number_of_diagnoses (50) x max_number_of_symptoms (50)\n",
    "            word2vec symptpm_vector : max_number_of_symptoms (126) x number_of_diagnoses (50)\n",
    "            diagnoses_vector = number_of_diagnoses\n",
    "            symptom_count = number of symtoms for current record\n",
    "        \"\"\"\n",
    "        tfidf_symp_vec, w2v_symp_vec, diag_vec, symp_list = self.hadm_list[index]\n",
    "        \n",
    "        # Create symptom vector for this admission record\n",
    "        return torch.tensor(tfidf_symp_vec.T, dtype=torch.float), torch.tensor(w2v_symp_vec.T, dtype=torch.float), torch.tensor(diag_vec, dtype=torch.float), len(symp_list)\n",
    "    \n",
    "    def create_symptom_vector_with_tfidf(self, symp_list):\n",
    "        # Convert Symptom text list to symptom index list\n",
    "        symptom_idx_list = self.generate_tfidf_based_embedding(symp_list)\n",
    "        \n",
    "        if len(symptom_idx_list) == 0:\n",
    "            return None\n",
    "        \n",
    "        symptom_vector = np.zeros((MAX_NUMBER_OF_DISEASE, MAX_SYMPTOMS))\n",
    "        # Populate Symptom Vector by getting corresponding embeddings from TF-IDF vector\n",
    "        for index, symptom_idx in enumerate(symptom_idx_list):\n",
    "            # print(f\"Symptom vector index: {index}, symptom index : {symptom_idx} \\n {self.tfidf_weights.iloc[:,symptom_idx]}\")\n",
    "            symptom_vector[:, index] = self.tfidf_weights.iloc[:,symptom_idx]\n",
    "        \n",
    "        return symptom_vector\n",
    "        \n",
    "\n",
    "    def create_symptom_vector_with_word2vec(self, symp_list):\n",
    "        # Create a 2d vector of symptoms (X)\n",
    "        symp_vec = np.zeros((WORD2VEC_NUM_FEATURES, MAX_SYMPTOMS))\n",
    "        \n",
    "        # We take max of 50 symptoms from each discharge summaries note\n",
    "        for index, symptom in enumerate(symp_list[:50]):\n",
    "            symp_vec[:, index] = self.generate_word2vec_based_embedding(symptom)\n",
    "        \n",
    "        return symp_vec\n",
    "        \n",
    "    def generate_word2vec_based_embedding(self, symptom):\n",
    "        \n",
    "        # If present in cache, return from cache\n",
    "        if symptom in self.word2vec_embedding_cache:\n",
    "            return self.word2vec_embedding_cache[symptom]\n",
    "        \n",
    "        symp_words = symptom.split()\n",
    "        symp_vec = np.zeros((WORD2VEC_NUM_FEATURES))\n",
    "        for word in symp_words:\n",
    "            # Get the word embedding\n",
    "            key = re.sub(r\"[^a-zA-Z0-9]\",\"\", word.lower())\n",
    "            if key in self.model_w2v:\n",
    "                symp_vec = symp_vec + self.model_w2v[key]\n",
    "        symp_vec = symp_vec / len(symp_words)\n",
    "        \n",
    "        # Save embedding in cache for future\n",
    "        self.word2vec_embedding_cache[symptom] = symp_vec\n",
    "        \n",
    "        return symp_vec\n",
    "    \n",
    "    # Converts symptom list to symptom vector\n",
    "    def generate_tfidf_based_embedding(self, symp_list):            \n",
    "        symp_index_list = []  \n",
    "        # only consider notes with symptoms count more than 1\n",
    "        if len(symp_list) > 1:\n",
    "            for symptom in symp_list:\n",
    "                if symptom in self.symptom_dict:\n",
    "                    symp_index_list.append(self.symptom_dict[symptom])\n",
    "        # print(f\"symp_index_list[:MAX_SYMPTOMS] -- {symp_index_list[:MAX_SYMPTOMS]}\")\n",
    "        return symp_index_list[:MAX_SYMPTOMS]\n",
    "    \n",
    "    def create_diagnosis_vector(self, diagnoses_list):\n",
    "        diag_vector = np.zeros((MAX_NUMBER_OF_DISEASE)) \n",
    "        # only consider notes with symptoms count more than 1\n",
    "        for diagnoses in diagnoses_list:\n",
    "            if diagnoses in self.icd9_dict:\n",
    "                # self.icd9_dict[diagnoses] is the index of disease\n",
    "                diag_vector[self.icd9_dict[diagnoses]] = 1\n",
    "\n",
    "        return diag_vector   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0593129",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SymptomCustomDataset(SYMPTOM_DISEASE_DICT_FILE_PATH, tfidf_weights, word2vec_model)\n",
    "train_size = int(len(dataset)*0.8)\n",
    "test_size = int(len(dataset)*0.1)\n",
    "# train_size = 20000\n",
    "# test_size = 2000\n",
    "validation_size = len(dataset)  - (train_size + test_size)\n",
    "train_dataset, test_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, validation_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "99b4739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5039"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb472e7",
   "metadata": {},
   "source": [
    "**Validate dataset created is with right size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da02b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size : 30000\n",
      "tfidf_symptom_rep.shape : torch.Size([50, 100])\n",
      "w2v_symptom_rep.shape : torch.Size([50, 128])\n",
      "diag_item.shape : tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6813e-02,  1.3691e-02, -2.1987e-03, -1.7290e-01,  3.2518e-01,\n",
       "        -2.8748e-02,  2.7833e-02,  1.3619e-01,  1.2748e-01, -3.0961e-01,\n",
       "        -2.4998e-01, -1.4167e-02,  1.6350e-01, -1.4159e-01,  6.9021e-02,\n",
       "         1.9138e-01, -5.0848e-01,  3.0326e-01, -5.6162e-03,  3.5649e-01,\n",
       "        -1.5401e-01, -6.5101e-02,  1.3688e-01,  6.0988e-02, -1.9457e-01,\n",
       "        -4.5802e-02, -3.4792e-01,  1.4945e-01,  2.1323e-02,  1.3801e-01,\n",
       "         1.1557e-01,  1.0230e-01,  3.5216e-01, -2.3127e-01,  4.3945e-01,\n",
       "         2.8974e-01, -3.2591e-01,  2.0405e-01, -5.6875e-02, -2.0529e-02,\n",
       "         3.4332e-01, -3.1652e-02, -2.4417e-01, -8.1900e-02,  1.2570e-02,\n",
       "        -5.8611e-02, -2.6748e-01,  2.3834e-01,  1.7938e-01,  7.6852e-02,\n",
       "         1.8585e-01,  1.3249e-01,  2.8239e-01, -4.1249e-01,  1.3322e-01,\n",
       "        -2.3322e-01,  1.8220e-01, -1.5826e-01,  1.5149e-02, -2.2592e-02,\n",
       "         1.0290e-01,  1.5922e-01, -7.5759e-02, -5.1029e-02,  1.5701e-01,\n",
       "         4.9979e-01, -2.2250e-02,  2.7358e-01, -2.8691e-01, -4.3604e-02,\n",
       "        -2.4861e-01, -3.1300e-01,  2.2460e-01,  3.8859e-01,  2.0667e-01,\n",
       "        -3.5689e-01, -4.2295e-01, -1.7508e-01,  1.1378e-01,  1.7730e-01,\n",
       "        -2.9904e-01, -2.0426e-01, -1.2060e-01,  4.1718e-01, -9.3435e-02,\n",
       "         1.7176e-01,  2.2122e-01,  6.4051e-03,  7.4813e-02,  2.7821e-02,\n",
       "         4.4843e-01, -3.3259e-01,  1.1432e-01,  1.7816e-01, -1.2321e-01,\n",
       "        -6.9090e-02, -7.5198e-02, -6.3094e-02,  4.2131e-02,  2.9753e-02,\n",
       "        -1.5359e-01, -2.4505e-01, -2.8946e-02,  2.3760e-01, -1.8185e-02,\n",
       "         2.1850e-01,  6.6789e-02,  7.9850e-02,  3.9966e-01, -2.8256e-01,\n",
       "        -4.1441e-01,  5.0283e-04,  1.0167e-01, -1.8653e-01, -8.3982e-02,\n",
       "        -3.8870e-01, -2.2950e-01, -1.5580e-01,  1.6226e-01, -2.6851e-01,\n",
       "         6.2752e-02, -1.1227e-01,  7.2565e-02,  2.8833e-01, -1.0834e-02,\n",
       "        -4.9529e-01, -3.8397e-01, -1.6943e-01], dtype=torch.float64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Dataset size : {len(dataset)}\")\n",
    "tfidf_symptom_rep, w2v_symptom_rep, diag_item, symptom_len = dataset[8]\n",
    "\n",
    "print(f\"tfidf_symptom_rep.shape : {tfidf_symptom_rep.shape}\")\n",
    "print(f\"w2v_symptom_rep.shape : {w2v_symptom_rep.shape}\")\n",
    "print(f\"diag_item.shape : {diag_item}\")\n",
    "assert tfidf_symptom_rep.shape == (MAX_SYMPTOMS, MAX_NUMBER_OF_DISEASE), \"Incorrect Symptom representation shape.\"\n",
    "assert w2v_symptom_rep.shape == (MAX_SYMPTOMS, WORD2VEC_NUM_FEATURES), \"Incorrect Symptom representation shape.\"\n",
    "assert diag_item.shape == (MAX_NUMBER_OF_DISEASE, ), \"Incorrect diagnoses labels\"\n",
    "w2v_symptom_rep[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019be4e",
   "metadata": {},
   "source": [
    "### 2.2 Define Symptom to Disease to BiLSTM Model (which uses TF-IDF based represenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd13d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymptomToDiseaseBiLstm(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, batch_size):\n",
    "        super(SymptomToDiseaseBiLstm, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=0.8)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, symp_length):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "\n",
    "        # x = torch.nn.utils.rnn.pack_padded_sequence(x, symp_length, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        out, (ht, ct) = self.bilstm(x, (h0, c0))\n",
    "        \n",
    "        # out, _ = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "sym_disease_model = SymptomToDiseaseBiLstm(MAX_NUMBER_OF_DISEASE, 100, 2, MAX_NUMBER_OF_DISEASE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376364b3",
   "metadata": {},
   "source": [
    "### 2.3 Training and inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "271093ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a649a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_padded_pred_and_true_labels(y_pred, y_true, symptom_length_vector):\n",
    "    \n",
    "    print(f\"y_pred.shape: {y_pred.shape}, y_true.shape: {y_true.shape}, symptom_length_vector: {symptom_length_vector.shape}\")\n",
    "    # Create a mask which will have all padded field to be zero\n",
    "    \n",
    "    mask_vector = np.ones(y_pred.shape)\n",
    "    idx = 0\n",
    "    for symptom_length in symptom_length_vector:\n",
    "        mask_vector[idx,symptom_length:] = 0\n",
    "        idx += 1\n",
    "        \n",
    "    mask = torch.tensor(mask_vector)\n",
    "    mask_1 = mask.view(-1)\n",
    "    mask_1 = mask_1.ge(1)\n",
    "    \n",
    "    y_pred_1 = y_pred.view(-1)\n",
    "    y_true_1 = y_true.view(-1)\n",
    "    \n",
    "    y_pred_final = torch.masked_select(y_pred_1, mask_1)\n",
    "    y_true_final = torch.masked_select(y_true_1, mask_1)\n",
    "    \n",
    "    print(f\"y_pred_final.shape: {y_pred_final.shape}, y_true_final.shape: {y_true_final.shape}\")\n",
    "    return y_pred_final, y_true_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cef6667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def eval(model, test_loader, is_tf_idf_data):\n",
    "    \n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: model\n",
    "        test_loader: dataloader\n",
    "        \n",
    "    OUTPUT:\n",
    "        precision: overall micro precision score\n",
    "        recall: overall micro recall score\n",
    "        f1: overall micro f1 score\n",
    "        \n",
    "    REFERENCE: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    for tf_idf_seq, word2vec_seq, labels, symp_len in test_loader:\n",
    "        data = tf_idf_seq if is_tf_idf_data else word2vec_seq\n",
    "        y_prob = model(data, symp_len)\n",
    "        y_hat = (y_prob > DISEASE_THRESHOLD).int()      \n",
    "\n",
    "        #y_hat, labels = get_non_padded_pred_and_true_labels(y_hat.detach().to('cpu'), labels.detach().to('cpu'), symp_len)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, labels.detach().to('cpu')), dim=0)\n",
    "        \n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    auc = roc_auc_score(y_true, y_pred, average='micro')\n",
    "    return p, r, f, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6133d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, n_epochs, optimizer, crirerion, is_tf_idf_data):\n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: the model\n",
    "        train_loader: dataloder\n",
    "        val_loader: dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for tf_idf_seq, word2vec_seq, y_true, symp_len in train_loader:\n",
    "            data = tf_idf_seq if is_tf_idf_data else word2vec_seq\n",
    "                \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(data, symp_len)\n",
    "            \n",
    "            loss = criterion(y_hat, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, auc = eval(model, test_loader, is_tf_idf_data)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, auc: {:.2f}'.format(epoch+1, p, r, f, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02be8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "sym_diag_optimizer = optim.Adam(sym_disease_model.parameters(), lr=0.001)\n",
    "sym_diag_criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0a1a60b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.239751\n",
      "Epoch: 1 \t Validation p: 0.32, r:0.39, f: 0.35, auc: 0.66\n",
      "Epoch: 2 \t Training Loss: 0.234632\n",
      "Epoch: 2 \t Validation p: 0.32, r:0.40, f: 0.36, auc: 0.66\n",
      "Epoch: 3 \t Training Loss: 0.230612\n",
      "Epoch: 3 \t Validation p: 0.35, r:0.40, f: 0.37, auc: 0.67\n",
      "Epoch: 4 \t Training Loss: 0.224973\n",
      "Epoch: 4 \t Validation p: 0.36, r:0.44, f: 0.39, auc: 0.68\n",
      "Epoch: 5 \t Training Loss: 0.219799\n",
      "Epoch: 5 \t Validation p: 0.39, r:0.42, f: 0.40, auc: 0.68\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "train(sym_disease_model, train_loader, test_loader, n_epochs, sym_diag_optimizer, sym_diag_criterion, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ccd28",
   "metadata": {},
   "source": [
    "#### Load Symptom to Disease Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ad6a7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sym_disease_model, SYMPTOM_TO_DIAGNOSE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe375d1",
   "metadata": {},
   "source": [
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.239751\n",
    "Epoch: 1 \t Validation p: 0.32, r:0.39, f: 0.35, auc: 0.66\n",
    "Epoch: 2 \t Training Loss: 0.234632\n",
    "Epoch: 2 \t Validation p: 0.32, r:0.40, f: 0.36, auc: 0.66\n",
    "Epoch: 3 \t Training Loss: 0.230612\n",
    "Epoch: 3 \t Validation p: 0.35, r:0.40, f: 0.37, auc: 0.67\n",
    "Epoch: 4 \t Training Loss: 0.224973\n",
    "Epoch: 4 \t Validation p: 0.36, r:0.44, f: 0.39, auc: 0.68\n",
    "Epoch: 5 \t Training Loss: 0.219799\n",
    "Epoch: 5 \t Validation p: 0.39, r:0.42, f: 0.40, auc: 0.68\n",
    "Epoch: 6 \t Training Loss: 0.239751\n",
    "Epoch: 6 \t Validation p: 0.32, r:0.39, f: 0.35, auc: 0.66\n",
    "Epoch: 7 \t Training Loss: 0.234632\n",
    "Epoch: 7 \t Validation p: 0.32, r:0.40, f: 0.36, auc: 0.66\n",
    "Epoch: 8 \t Training Loss: 0.230612\n",
    "Epoch: 8 \t Validation p: 0.35, r:0.40, f: 0.37, auc: 0.67\n",
    "Epoch: 9 \t Training Loss: 0.224973\n",
    "Epoch: 9 \t Validation p: 0.36, r:0.44, f: 0.39, auc: 0.68\n",
    "Epoch: 10 \t Training Loss: 0.219799\n",
    "Epoch: 10 \t Validation p: 0.39, r:0.42, f: 0.40, auc: 0.68\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea7a49",
   "metadata": {},
   "source": [
    "## 3.0 Symptom to Symptom BiLSTM Model (for Word2Vec based symptom representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "711046c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymptomToSymptomLstm(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(SymptomToSymptomLstm, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=0.8)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, symp_length):\n",
    "        # Perform forward step\n",
    "        out, (ht, ct) = self.bilstm(x)\n",
    "        \n",
    "        # print(f\"out.shape : {out.shape}, ht.shape : {ht.shape}, ct.shape : {ct.shape}\")\n",
    "        # returning last layer of output from hidden state\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        out = self.sigmoid(out)\n",
    "        # Return model output\n",
    "        return out\n",
    "\n",
    "symp_to_symp_model = SymptomToSymptomLstm(128, 256, 2, MAX_NUMBER_OF_DISEASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bbee4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "sym_to_sym_optimizer = optim.Adam(symp_to_symp_model.parameters(), lr=0.001)\n",
    "sym_to_sym_criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "69b21eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.237278\n",
      "Epoch: 1 \t Validation p: 0.34, r:0.40, f: 0.37, auc: 0.67\n",
      "Epoch: 2 \t Training Loss: 0.232318\n",
      "Epoch: 2 \t Validation p: 0.34, r:0.42, f: 0.37, auc: 0.67\n",
      "Epoch: 3 \t Training Loss: 0.227837\n",
      "Epoch: 3 \t Validation p: 0.36, r:0.42, f: 0.39, auc: 0.68\n",
      "Epoch: 4 \t Training Loss: 0.221444\n",
      "Epoch: 4 \t Validation p: 0.39, r:0.42, f: 0.40, auc: 0.68\n",
      "Epoch: 5 \t Training Loss: 0.218801\n",
      "Epoch: 5 \t Validation p: 0.37, r:0.45, f: 0.41, auc: 0.69\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 5\n",
    "train(symp_to_symp_model, train_loader, test_loader, n_epochs, sym_to_sym_optimizer, sym_to_sym_criterion, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55894d31",
   "metadata": {},
   "source": [
    "#### Save Symptom to symptom model on filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7dedc712",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(symp_to_symp_model, SYMPTOM_TO_SYMPTOM_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84b119",
   "metadata": {},
   "source": [
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.254184\n",
    "Epoch: 1 \t Validation p: 0.28, r:0.32, f: 0.30, auc: 0.63\n",
    "Epoch: 2 \t Training Loss: 0.250877\n",
    "Epoch: 2 \t Validation p: 0.30, r:0.35, f: 0.32, auc: 0.64\n",
    "Epoch: 3 \t Training Loss: 0.248819\n",
    "Epoch: 3 \t Validation p: 0.30, r:0.35, f: 0.32, auc: 0.64\n",
    "Epoch: 4 \t Training Loss: 0.247505\n",
    "Epoch: 4 \t Validation p: 0.30, r:0.35, f: 0.33, auc: 0.64\n",
    "Epoch: 5 \t Training Loss: 0.245524\n",
    "Epoch: 5 \t Validation p: 0.30, r:0.35, f: 0.32, auc: 0.64\n",
    "Epoch: 6 \t Training Loss: 0.237278\n",
    "Epoch: 6 \t Validation p: 0.34, r:0.40, f: 0.37, auc: 0.67\n",
    "Epoch: 7 \t Training Loss: 0.232318\n",
    "Epoch: 7 \t Validation p: 0.34, r:0.42, f: 0.37, auc: 0.67\n",
    "Epoch: 8 \t Training Loss: 0.227837\n",
    "Epoch: 8 \t Validation p: 0.36, r:0.42, f: 0.39, auc: 0.68\n",
    "Epoch: 9 \t Training Loss: 0.221444\n",
    "Epoch: 9 \t Validation p: 0.39, r:0.42, f: 0.40, auc: 0.68\n",
    "Epoch: 10 \t Training Loss: 0.218801\n",
    "Epoch: 10\t Validation p: 0.37, r:0.45, f: 0.41, auc: 0.69\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6ed42",
   "metadata": {},
   "source": [
    "### 4.0 Combining two models with weighted mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f102ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_statistics(type_of_stat, y_true, y_pred, average='micro'):\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    auc = roc_auc_score(y_true, y_pred, average='micro')\n",
    "    print('{} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, auc: {:.2f}'.format(type_of_stat, p, r, f, auc))\n",
    "    return p, r, f, auc\n",
    "\n",
    "\n",
    "def combined_prediction(sym_disease_model, symp_to_symp_model, test_loader, weight_of_tfidf):\n",
    "    \n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: model\n",
    "        test_loader: dataloader\n",
    "        \n",
    "    OUTPUT:\n",
    "        precision: overall micro precision score\n",
    "        recall: overall micro recall score\n",
    "        f1: overall micro f1 score\n",
    "        \n",
    "    REFERENCE: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \"\"\"\n",
    "    y_pred_1 = torch.LongTensor()\n",
    "    y_pred_2 = torch.LongTensor()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    for tf_idf_seq, word2vec_seq, labels, symp_len in test_loader:\n",
    "\n",
    "        y_prob_1 = sym_disease_model(tf_idf_seq, symp_len)\n",
    "        y_prob_2 = symp_to_symp_model(word2vec_seq, symp_len)\n",
    "        \n",
    "        y_prob = y_prob_1 * weight_of_tfidf + y_prob_2 * (1.0 - weight_of_tfidf)\n",
    "        \n",
    "        y_hat_1 = (y_prob_1 > DISEASE_THRESHOLD).int()\n",
    "        y_hat_2 = (y_prob_2 > DISEASE_THRESHOLD).int()\n",
    "        y_hat = (y_prob > DISEASE_THRESHOLD).int()      \n",
    "\n",
    "        #y_hat, labels = get_non_padded_pred_and_true_labels(y_hat.detach().to('cpu'), labels.detach().to('cpu'), symp_len)\n",
    "        \n",
    "        y_pred_1 = torch.cat((y_pred_1,  y_hat_1.detach().to('cpu')), dim=0)\n",
    "        y_pred_2 = torch.cat((y_pred_2,  y_hat_2.detach().to('cpu')), dim=0)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, labels.detach().to('cpu')), dim=0)\n",
    "        \n",
    "    performance_statistics(\"Symptom-Diag Statistics (TF-IDF)\", y_true, y_pred_1)\n",
    "    performance_statistics(\"Symptom-Sympton Statistics (Word2Vec)\", y_true, y_pred_2)\n",
    "    p, r, f, auc = performance_statistics(\"Combined (Word2Vec)\", y_true, y_pred)\n",
    "\n",
    "    return p, r, f, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c6df6d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symptom-Diag Statistics (TF-IDF) \t Validation p: 0.39, r:0.42, f: 0.40, auc: 0.68\n",
      "Symptom-Sympton Statistics (Word2Vec) \t Validation p: 0.37, r:0.45, f: 0.41, auc: 0.69\n",
      "Combined (Word2Vec) \t Validation p: 0.39, r:0.44, f: 0.41, auc: 0.69\n",
      "\n",
      "Final \t Validation p: 0.39, r:0.44, f: 0.41, auc: 0.69\n"
     ]
    }
   ],
   "source": [
    "p, r, f, auc = combined_prediction(sym_disease_model, symp_to_symp_model, test_loader, 0.5)\n",
    "\n",
    "print('\\nFinal \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, auc: {:.2f}'.format(p, r, f, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1589d4c",
   "metadata": {},
   "source": [
    "<code>\n",
    "Symptom-Diag Statistics (TF-IDF) \t Validation p: 0.39, r:0.42, f: 0.40, auc: 0.68\n",
    "Symptom-Sympton Statistics (Word2Vec) \t Validation p: 0.30, r:0.35, f: 0.32, auc: 0.64\n",
    "Combined (Word2Vec) \t Validation p: 0.37, r:0.41, f: 0.39, auc: 0.68\n",
    "\n",
    "Final \t Validation p: 0.37, r:0.41, f: 0.39, auc: 0.68\n",
    "</code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

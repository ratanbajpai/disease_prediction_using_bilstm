{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0125c6",
   "metadata": {},
   "source": [
    "<h3> Training BiLSTM Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4978a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8264555",
   "metadata": {},
   "source": [
    "# BiLSTM Model Training\n",
    "\n",
    "This notebook implements the BiLSTM model which will take TF-IDF based symptom representation and Word2Vec based symptom representation and predicts diagnoses codes.\n",
    "\n",
    "---\n",
    "\n",
    "- Input : symptom_disease_dict_{RUN_TAG}.json - Contains HADM_ID to Symptom text and Diagnosis mapping as json object\n",
    "- Input : icd9_dict_{RUN_TAG}.json - Contains ICD9 Codes of TOP N Diagnoses\n",
    "- Input : weight_i_j_norm{tag}.csv - TF-IDF weights for symptom representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2728c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory : /Users/vijaymi/Studies/CS-598-DL4Health/Project/135-Disease-Inference-Method/disease_pred_using_bilstm/source\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory : {cwd}\")\n",
    "# Let's define some constants that will be used below in our processing\n",
    "MAX_NUMBER_OF_DISEASE = 50\n",
    "MAX_SYMPTOMS = 50\n",
    "BATCH_SIZE=400\n",
    "RUN_TAG = \"_v2.0\"\n",
    "data_dir = cwd + \"/../../data/\"\n",
    "SYMPTOM_DISEASE_DICT_FILE_PATH = data_dir + f\"symptom_disease_dict_{RUN_TAG}.json\"\n",
    "ICD9_FILE_PATH = data_dir + f\"icd9_dict_{RUN_TAG}.json\"\n",
    "SYMPTOM_DICT_FILE_PATH = data_dir + f\"symptoms_dict_{RUN_TAG}.json\"\n",
    "TF_IDF_WEIGHTS_FILE_PATH = data_dir + f\"weight_i_j_{RUN_TAG}.csv\"\n",
    "TF_IDF_NORM_WEIGHTS_FILE_PATH = data_dir + f\"weight_i_j_norm_{RUN_TAG}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8035f",
   "metadata": {},
   "source": [
    "## 1. Loading all the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8834a243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3980</th>\n",
       "      <th>3981</th>\n",
       "      <th>3982</th>\n",
       "      <th>3983</th>\n",
       "      <th>3984</th>\n",
       "      <th>3985</th>\n",
       "      <th>3986</th>\n",
       "      <th>3987</th>\n",
       "      <th>3988</th>\n",
       "      <th>3989</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3990 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8         9  ...      3980  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.817708  ...  0.090909   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.802083  ...  0.272727   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.000000  ...  0.545455   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.739583  ...  0.090909   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.630208  ...  0.000000   \n",
       "\n",
       "       3981   3982      3983      3984      3985      3986   3987  3988   3989  \n",
       "0  0.666667  0.125  0.833333  0.666667  0.714286  0.500000  1.000   0.2  1.000  \n",
       "1  0.000000  0.625  0.500000  0.111111  0.571429  0.333333  0.500   0.4  0.500  \n",
       "2  0.666667  0.375  0.500000  0.666667  0.714286  0.833333  0.875   0.6  0.000  \n",
       "3  0.166667  0.500  0.333333  0.222222  0.285714  0.166667  0.250   0.0  0.500  \n",
       "4  0.166667  0.125  0.500000  0.111111  0.428571  0.500000  0.875   0.2  0.625  \n",
       "\n",
       "[5 rows x 3990 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd9_dict = None\n",
    "with open(ICD9_FILE_PATH, 'r') as f:\n",
    "            icd9_dict = json.load(f)\n",
    "        \n",
    "symptom_disease_dict = None\n",
    "with open(SYMPTOM_DISEASE_DICT_FILE_PATH, 'r') as f:\n",
    "            symptom_disease_dict = json.load(f)\n",
    "\n",
    "symptoms_dict = None\n",
    "with open(SYMPTOM_DICT_FILE_PATH, 'r') as f:\n",
    "    symptoms_dict = json.load(f)\n",
    "    \n",
    "tfidf_weights = pd.read_csv(TF_IDF_NORM_WEIGHTS_FILE_PATH)\n",
    "tfidf_weights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcad268",
   "metadata": {},
   "source": [
    "## 2. Symptom to Disease BiLSTM Model (for TF-IDF based Symptom representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf45e64",
   "metadata": {},
   "source": [
    "### 2.1 Define Custom Loader for Symtom to Diagnoses based BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fc365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SymptomToDiagnosesBiLSTMDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filename):        \n",
    "        self.hadm_id_map = {}\n",
    "        \n",
    "        # TF-IDF Weights\n",
    "        self.tfidf_weights = pd.read_csv(TF_IDF_NORM_WEIGHTS_FILE_PATH)\n",
    "        \n",
    "        # Symptom dictionary\n",
    "        with open(SYMPTOM_DICT_FILE_PATH, 'r') as f:\n",
    "            self.symptom_dict = json.load(f)\n",
    "        \n",
    "        with open(ICD9_FILE_PATH, 'r') as f:\n",
    "            self.icd9_dict = json.load(f)\n",
    "        \n",
    "        # read in the data files\n",
    "        self.hadm_list = self.process_raw_data(filename)\n",
    "        \n",
    "        \n",
    "    def process_raw_data(self, filename):\n",
    "        symptom_disease_dict = None\n",
    "        with open(filename, 'r') as f:\n",
    "            symptom_disease_dict = json.load(f)\n",
    "        hadm_list = []\n",
    "\n",
    "        # Collecting all records for one admission as a tuple of symptoms list and diagnoses list\n",
    "        for hadm_id in symptom_disease_dict.keys():            \n",
    "            symp_list, icd9_list = symptom_disease_dict[hadm_id]\n",
    "            symp_vec = self.create_symptom_vector(symp_list)\n",
    "            diag_vec = self.create_diagnosis_vector(icd9_list)\n",
    "            \n",
    "            hadm_list.append((symp_vec, diag_vec))\n",
    "        \n",
    "        return hadm_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hadm_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            Output:\n",
    "            symptpm_vector : max_number_of_symptoms (50) x number_of_diagnoses (50)\n",
    "            diagnoses_vector = number_of_diagnoses\n",
    "            symptom_count = number of symtoms for current record\n",
    "        \"\"\"\n",
    "        symptom_list, diagnosis_list = self.hadm_list[index]\n",
    "        \n",
    "        # Create symptom vector for this admission record\n",
    "        symptom_vector = np.zeros((MAX_SYMPTOMS, MAX_NUMBER_OF_DISEASE))\n",
    "        \n",
    "        # Create Diagnosis vector to keep true labels\n",
    "        diag_vector = np.zeros((MAX_NUMBER_OF_DISEASE))\n",
    "\n",
    "        # Populate Symptom Vector by getting corresponding embeddings from TF-IDF vector\n",
    "        for index, symptom_idx in enumerate(symptom_list):\n",
    "            # print(f\"Symptom vector index: {index}, symptom index : {symptom_idx} \\n {self.tfidf_weights.iloc[:,symptom_idx]}\")\n",
    "            symptom_vector[index] = self.tfidf_weights.iloc[:,symptom_idx]\n",
    "            \n",
    "        # Populate disease vector   \n",
    "        for diagnosis_index in diagnosis_list:\n",
    "            diag_vector[diagnosis_index] = 1\n",
    "                # print(f\"icd code : {icd_code}, diagnosis_index : {diagnosis_index}\")\n",
    "        return torch.tensor(symptom_vector.T, dtype=torch.float), torch.tensor(diag_vector, dtype=torch.float), len(symptom_list)\n",
    "    \n",
    "    def create_symptom_vector(self, symp_list):\n",
    "        symp_index_list = []  \n",
    "        # only consider notes with symptoms count more than 1\n",
    "        if len(symp_list) > 1:\n",
    "            for symptom in symp_list:\n",
    "                if symptom in self.symptom_dict:\n",
    "                    symp_index_list.append(self.symptom_dict[symptom])\n",
    "        # print(f\"symp_index_list[:MAX_SYMPTOMS] -- {symp_index_list[:MAX_SYMPTOMS]}\")\n",
    "        return symp_index_list[:MAX_SYMPTOMS]\n",
    "    \n",
    "    def create_diagnosis_vector(self, diagnoses_list):\n",
    "        diag_index_list = []  \n",
    "        # only consider notes with symptoms count more than 1\n",
    "        for diagnoses in diagnoses_list:\n",
    "            if diagnoses in self.icd9_dict:\n",
    "                diag_index_list.append(self.icd9_dict[diagnoses])\n",
    "        return diag_index_list   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0593129",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SymptomToDiagnosesBiLSTMDataset(SYMPTOM_DISEASE_DICT_FILE_PATH)\n",
    "# train_size = int(len(dataset)*0.8)\n",
    "# test_size = int(len(dataset)*0.2)\n",
    "train_size = 20000\n",
    "test_size = 2000\n",
    "validation_size = len(dataset)  - (train_size + test_size)\n",
    "train_dataset, test_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, validation_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb472e7",
   "metadata": {},
   "source": [
    "**Validate dataset created is with right size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da02b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size : 49352\n",
      "symptom_item.shape : torch.Size([50, 50])\n",
      "diag_item.shape : tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1053, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3684, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0789, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0526, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1579, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Dataset size : {len(dataset)}\")\n",
    "symptom_item, diag_item, symptom_len = dataset[8]\n",
    "\n",
    "print(f\"symptom_item.shape : {symptom_item.shape}\")\n",
    "print(f\"diag_item.shape : {diag_item}\")\n",
    "assert symptom_item.shape == (MAX_SYMPTOMS, MAX_NUMBER_OF_DISEASE), \"Incorrect Symptom representation shape.\"\n",
    "assert diag_item.shape == (MAX_NUMBER_OF_DISEASE, ), \"Incorrect diagnoses labels\"\n",
    "symptom_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019be4e",
   "metadata": {},
   "source": [
    "### 2.2 Define Symptom to Disease to BiLSTM Model (which uses TF-IDF based represenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd13d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymptomToDiseaseBiLstm(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, batch_size):\n",
    "        super(SymptomToDiseaseBiLstm, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=0.8)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, symp_length):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "\n",
    "        # x = torch.nn.utils.rnn.pack_padded_sequence(x, symp_length, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        out, (ht, ct) = self.bilstm(x, (h0, c0))\n",
    "        \n",
    "        # out, _ = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "sym_disease_model = SymptomToDiseaseBiLstm(MAX_SYMPTOMS, 100, 2, MAX_NUMBER_OF_DISEASE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376364b3",
   "metadata": {},
   "source": [
    "### 2.3 Training and inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271093ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(sym_disease_model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a649a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_padded_pred_and_true_labels(y_pred, y_true, symptom_length_vector):\n",
    "    \n",
    "    print(f\"y_pred.shape: {y_pred.shape}, y_true.shape: {y_true.shape}, symptom_length_vector: {symptom_length_vector.shape}\")\n",
    "    # Create a mask which will have all padded field to be zero\n",
    "    \n",
    "    mask_vector = np.ones(y_pred.shape)\n",
    "    idx = 0\n",
    "    for symptom_length in symptom_length_vector:\n",
    "        mask_vector[idx,symptom_length:] = 0\n",
    "        idx += 1\n",
    "        \n",
    "    mask = torch.tensor(mask_vector)\n",
    "    mask_1 = mask.view(-1)\n",
    "    mask_1 = mask_1.ge(1)\n",
    "    \n",
    "    y_pred_1 = y_pred.view(-1)\n",
    "    y_true_1 = y_true.view(-1)\n",
    "    \n",
    "    y_pred_final = torch.masked_select(y_pred_1, mask_1)\n",
    "    y_true_final = torch.masked_select(y_true_1, mask_1)\n",
    "    \n",
    "    print(f\"y_pred_final.shape: {y_pred_final.shape}, y_true_final.shape: {y_true_final.shape}\")\n",
    "    return y_pred_final, y_true_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cef6667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "DISEASE_THRESHOLD = 0.20\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    \n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: model\n",
    "        test_loader: dataloader\n",
    "        \n",
    "    OUTPUT:\n",
    "        precision: overall micro precision score\n",
    "        recall: overall micro recall score\n",
    "        f1: overall micro f1 score\n",
    "        \n",
    "    REFERENCE: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    for sequences, labels, symp_len in test_loader:\n",
    "        y_prob = model(sequences, symp_len)\n",
    "        y_hat = (y_prob > DISEASE_THRESHOLD).int()\n",
    "#         print(f\"y_prob: {y_hat}\")\n",
    "#         print(f\"labels: {labels}\")\n",
    "        #y_hat, labels = get_non_padded_pred_and_true_labels(y_hat.detach().to('cpu'), labels.detach().to('cpu'), symp_len)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, labels.detach().to('cpu')), dim=0)\n",
    "        \n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    auc = roc_auc_score(y_true, y_pred, average='micro')\n",
    "    return p, r, f, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6133d599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.358892\n",
      "Epoch: 1 \t Validation p: 0.28, r:0.44, f: 0.34, auc: 0.64\n",
      "Epoch: 2 \t Training Loss: 0.358633\n",
      "Epoch: 2 \t Validation p: 0.28, r:0.44, f: 0.34, auc: 0.64\n",
      "Epoch: 3 \t Training Loss: 0.358447\n",
      "Epoch: 3 \t Validation p: 0.29, r:0.43, f: 0.35, auc: 0.64\n",
      "Epoch: 4 \t Training Loss: 0.357412\n",
      "Epoch: 4 \t Validation p: 0.28, r:0.44, f: 0.34, auc: 0.64\n",
      "Epoch: 5 \t Training Loss: 0.354182\n",
      "Epoch: 5 \t Validation p: 0.30, r:0.43, f: 0.36, auc: 0.64\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, test_loader, n_epochs):\n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: the model\n",
    "        train_loader: dataloder\n",
    "        val_loader: dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, y_true, symp_len in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(sequences, symp_len)\n",
    "            \n",
    "            loss = criterion(y_hat, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, auc = eval(model, test_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, auc: {:.2f}'.format(epoch+1, p, r, f, auc))\n",
    "\n",
    "    \n",
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "train(sym_disease_model, train_loader, test_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe375d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "_100_v3 - 10 Epochs - Using non-normalized weights. lr=0.001\n",
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.236686\n",
    "Epoch: 1 \t Validation p: 0.34, r:0.39, f: 0.36, auc: 0.66\n",
    "Epoch: 2 \t Training Loss: 0.235472\n",
    "Epoch: 2 \t Validation p: 0.34, r:0.40, f: 0.37, auc: 0.66\n",
    "Epoch: 3 \t Training Loss: 0.233751\n",
    "Epoch: 3 \t Validation p: 0.35, r:0.39, f: 0.37, auc: 0.66\n",
    "Epoch: 4 \t Training Loss: 0.232628\n",
    "Epoch: 4 \t Validation p: 0.34, r:0.39, f: 0.37, auc: 0.66\n",
    "Epoch: 5 \t Training Loss: 0.232200\n",
    "Epoch: 5 \t Validation p: 0.35, r:0.39, f: 0.37, auc: 0.66\n",
    "</code>\n",
    "\n",
    "----------------\n",
    "\n",
    "n_epochs = 2, learning rate = 0.001 <br>\n",
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.332956\n",
    "Epoch: 1 \t Validation p: 0.35, r:0.51, f: 0.42, auc: 0.69\n",
    "Epoch: 2 \t Training Loss: 0.303654\n",
    "Epoch: 2 \t Validation p: 0.40, r:0.51, f: 0.45, auc: 0.70\n",
    "</code>\n",
    "         <code>\n",
    "Epoch: 1 \t Training Loss: 0.298307\n",
    "Epoch: 1 \t Validation p: 0.40, r:0.53, f: 0.45, auc: 0.71\n",
    "Epoch: 2 \t Training Loss: 0.294352\n",
    "Epoch: 2 \t Validation p: 0.38, r:0.57, f: 0.46, auc: 0.72\n",
    "Epoch: 3 \t Training Loss: 0.290162\n",
    "Epoch: 3 \t Validation p: 0.40, r:0.55, f: 0.46, auc: 0.72\n",
    "Epoch: 4 \t Training Loss: 0.286585\n",
    "Epoch: 4 \t Validation p: 0.39, r:0.57, f: 0.47, auc: 0.72\n",
    "Epoch: 5 \t Training Loss: 0.283719\n",
    "Epoch: 5 \t Validation p: 0.40, r:0.58, f: 0.47, auc: 0.73      \n",
    "    </code>\n",
    "\n",
    "<h5>n_epochs=5, learning_rate = 0.005</h5>\n",
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.292470\n",
    "Epoch: 1 \t Validation p: 0.36, r:0.59, f: 0.45, auc: 0.72\n",
    "Epoch: 2 \t Training Loss: 0.288039\n",
    "Epoch: 2 \t Validation p: 0.37, r:0.62, f: 0.46, auc: 0.73\n",
    "Epoch: 3 \t Training Loss: 0.284519\n",
    "Epoch: 3 \t Validation p: 0.38, r:0.60, f: 0.47, auc: 0.73\n",
    "Epoch: 4 \t Training Loss: 0.282809\n",
    "Epoch: 4 \t Validation p: 0.37, r:0.63, f: 0.46, auc: 0.74\n",
    "Epoch: 5 \t Training Loss: 0.281407\n",
    "Epoch: 5 \t Validation p: 0.38, r:0.61, f: 0.47, auc: 0.74\n",
    "</code>\n",
    "\n",
    "With Batch size of 400, starting fresh!\n",
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.400608\n",
    "Epoch: 1 \t Validation p: 0.28, r:0.40, f: 0.33, auc: 0.63\n",
    "Epoch: 2 \t Training Loss: 0.347110\n",
    "Epoch: 2 \t Validation p: 0.35, r:0.36, f: 0.35, auc: 0.63\n",
    "Epoch: 3 \t Training Loss: 0.326768\n",
    "Epoch: 3 \t Validation p: 0.37, r:0.44, f: 0.40, auc: 0.67\n",
    "Epoch: 4 \t Training Loss: 0.319100\n",
    "Epoch: 4 \t Validation p: 0.37, r:0.46, f: 0.41, auc: 0.67\n",
    "Epoch: 5 \t Training Loss: 0.312817\n",
    "Epoch: 5 \t Validation p: 0.36, r:0.54, f: 0.43, auc: 0.70\n",
    "    \n",
    "Epoch: 1 \t Training Loss: 0.304074\n",
    "Epoch: 1 \t Validation p: 0.38, r:0.52, f: 0.44, auc: 0.70\n",
    "Epoch: 2 \t Training Loss: 0.300410\n",
    "Epoch: 2 \t Validation p: 0.39, r:0.51, f: 0.44, auc: 0.70\n",
    "Epoch: 3 \t Training Loss: 0.299053\n",
    "Epoch: 3 \t Validation p: 0.38, r:0.54, f: 0.45, auc: 0.71\n",
    "Epoch: 4 \t Training Loss: 0.297172\n",
    "Epoch: 4 \t Validation p: 0.40, r:0.52, f: 0.45, auc: 0.70\n",
    "Epoch: 5 \t Training Loss: 0.294421\n",
    "Epoch: 5 \t Validation p: 0.38, r:0.56, f: 0.45, auc: 0.71\n",
    "</code>\n",
    "\n",
    "Number of layers in BiLSRT as 4. Very slow as well!\n",
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.691968\n",
    "Epoch: 1 \t Validation p: 0.13, r:1.00, f: 0.23, auc: 0.50\n",
    "Epoch: 2 \t Training Loss: 0.691965\n",
    "Epoch: 2 \t Validation p: 0.13, r:1.00, f: 0.23, auc: 0.50\n",
    "</code>\n",
    "\n",
    "Number of layers in BiLSRT as 3. Very slow as well!\n",
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.329327\n",
    "Epoch: 1 \t Validation p: 0.30, r:0.56, f: 0.39, auc: 0.69\n",
    "Epoch: 2 \t Training Loss: 0.320431\n",
    "Epoch: 2 \t Validation p: 0.33, r:0.53, f: 0.41, auc: 0.69\n",
    "Epoch: 3 \t Training Loss: 0.317443\n",
    "Epoch: 3 \t Validation p: 0.35, r:0.49, f: 0.41, auc: 0.68\n",
    "Epoch: 4 \t Training Loss: 0.315925\n",
    "Epoch: 4 \t Validation p: 0.34, r:0.52, f: 0.41, auc: 0.69\n",
    "Epoch: 5 \t Training Loss: 0.311251\n",
    "Epoch: 5 \t Validation p: 0.38, r:0.49, f: 0.43, auc: 0.69\n",
    "</code>\n",
    "\n",
    "10 Epoch run with 50 disease\n",
    "<code>\n",
    "Epoch: 1 \t Training Loss: 0.403777\n",
    "Epoch: 1 \t Validation p: 0.28, r:0.44, f: 0.35, auc: 0.64\n",
    "Epoch: 2 \t Training Loss: 0.354655\n",
    "Epoch: 2 \t Validation p: 0.33, r:0.42, f: 0.37, auc: 0.65\n",
    "Epoch: 3 \t Training Loss: 0.343463\n",
    "Epoch: 3 \t Validation p: 0.34, r:0.46, f: 0.39, auc: 0.66\n",
    "Epoch: 4 \t Training Loss: 0.337650\n",
    "Epoch: 4 \t Validation p: 0.33, r:0.49, f: 0.39, auc: 0.67\n",
    "Epoch: 5 \t Training Loss: 0.331578\n",
    "Epoch: 5 \t Validation p: 0.36, r:0.48, f: 0.41, auc: 0.68\n",
    "Epoch: 6 \t Training Loss: 0.323138\n",
    "Epoch: 6 \t Validation p: 0.36, r:0.50, f: 0.42, auc: 0.69\n",
    "Epoch: 7 \t Training Loss: 0.319433\n",
    "Epoch: 7 \t Validation p: 0.36, r:0.51, f: 0.43, auc: 0.69\n",
    "Epoch: 8 \t Training Loss: 0.317392\n",
    "Epoch: 8 \t Validation p: 0.39, r:0.48, f: 0.43, auc: 0.68\n",
    "Epoch: 9 \t Training Loss: 0.315443\n",
    "Epoch: 9 \t Validation p: 0.37, r:0.52, f: 0.43, auc: 0.69\n",
    "Epoch: 10 \t Training Loss: 0.313061\n",
    "Epoch: 10 \t Validation p: 0.38, r:0.52, f: 0.44, auc: 0.70\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea7a49",
   "metadata": {},
   "source": [
    "## 3.0 Symptom to Symptom BiLSTM Model (for Word2Vec based symptom representation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
